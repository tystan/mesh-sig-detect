---
title: "Report"
subtitle: "Signal detection of spontaneous medical device reports over time accounting for multiple comparisons"
author: "Ty Stanford, Lan Kelly et al."
format: 
  pdf:
    toc: true
    highlight-style: atom-one
    number-sections: true
editor: source
---


<!-- highlight-style supported themes: arrow, pygments, tango, espresso, zenburn, kate, monochrome, breezedark, haddock, atom-one, ayu, breeze, dracula, github, gruvbox, monokai, nord, oblivion, printing, radical, solarized, and vim. -->


```{R}
#| include: false
knitr::read_chunk('r/2_plot_results.R')
```


\newpage

# Set up

## Packages


```{R, libs}
```

## Load data


```{R, load_dat}
```




\newpage

# Methods

## Data aquisition

The data is thanks to [curtis-murray](https://github.com/curtis-murray) at his [MedicalDevicesNLP](https://github.com/curtis-murray/MedicalDevicesNLP) repo

* Natural language processing of the TGA spontaneous reports of medical device database (DAEN)
* Each record has an estimate of P(`topic == "pain"` | `Level`, `Doc`) using hierarchical stochastic block modelling (hSBM)
* P(`topic == "pain"` | `Level`, `Doc`) estimates for each record are roughly interpreted as the proportion of the NLP analysed free text that is considered as using/describing words related to pain

And example record and processing values:

* [to include here]



\newpage





## Analysis data


Signal detection of disproportionate adverse events (AEs) will often have tabulated count data accumulated over time. The data at time point $t$ can be summarised as below:

|         | AE(s) $\in Y$| AE(s) $\in \bar{Y}$ |
|:--------|---------:|----------:|
|Target exposure|       $a_t$|        $b_t$|
|Comparator exposure|       $c_t$|        $d_t$|

where

* AE(s) $Y$ is the set of AEs (or singular AE) of interest, 
* AE(s) $\bar{Y}$ is the complementary set to the AEs of interest, 
* *Target exposure* is the medical device(s) of interest,  
* *Comparator exposure* is the medical devices to which the *Target exposure* is being compared, and 
* $a_t$, $b_t$, $c_t$ and $d_t$ (all $\in \mathbb{Z}^{+}$) are the respective counts of AEs recorded up until (i.e., cumulative) time $t$.

In the motivating example of the pelvic mesh device, the contingency table can be written more specifically as


|         | Pain AEs | Not pain AEs  |
|:--------|---------:|----------:|
|Pelvic mesh|       $a_t$|        $b_t$|
|Comparator exposure|       $c_t$|        $d_t$|


where 

* *AEs pain* is the count of AEs that contain "pain" themes greater or equal to some pre-specified threshold $p_t \in (0,1)$ as estimated by the hSBM (that is, $P(\texttt{topic == "pain"} | \texttt{Level, Doc}) \geq p_t$), and
* *Comparator exposure* can be any relevant set of medical devices to compare the pelvic mesh to (e.g., hernia mesh or all other mesh devices or all other devices).

# The signal detection statistics over time

We will consider the three signal detection statistics below:

* Proportional reporting ratio (PRR),
* Bayesian Confidence Propagation Neural Network Information Component (BCPNN IC with MCMC CIs), and
* the maxSPRT statistic


As signal detection is being undertaken repeatedly as data are being accumulated, alpha spending needs to be considered. The below table classifies the aforementioned signal detection methods by their null hypothesis as well as whether they control for the family-wise error rate (FWER)


| Null hypothesis        | non-FWER version | FWER version |
|:--------|---------:|----------:|
| Ratio of pain AEs to all AEs in target and comparator groups has a ratio of 1 |      PRR |  binary, group sequential  maxSPRT|
|Independence of pain AEs and target group (based on marginal counts)|       IC |        IC with $\alpha$-spending scheme|


We will demonstrate how the group sequential binary maxSPRT, as described in previous work, is equivalent to a FWER-controlled PRR method of signal detection.



## Proportional reporting ratio (PRR) 


The PRR estimate is calculated  

$$
\widehat{\text{PRR}}_t = \frac{\frac{a_t}{a_t + b_t}}{\frac{c_t}{c_t+d_t}}.
$$
In the context of signal detection, an elevated proportional reporting ratio is of concern. Therefore the one-sided hypothesis test $H_0: \text{PRR} \leq 1$ (proportional reporting of the target is less than the comparator) is used and is not rejected until

$$
\widehat{\text{PRR}}_t 
{\times}
\exp \left\{{- Z_{\alpha}^{*}  \sqrt{\frac{1}{a_t} + \frac{1}{a_t + b_t} + \frac{1}{c_t} + \frac{1}{c_t+d_t}}}\right\} > 1
$$

at the $\alpha$ level where $Z_{\alpha}^{*}$ is the $(1-\alpha)^{\text{th}}$ quantile of the standard normal distribution. The above threshold is equivalent to the lower bound of the approximate $100(1-2\alpha)$\% confidence interval for a standard two-sided hypothesis test.





##  Bayesian Confidence Propagation Neural Network (BCPNN) Information Component (IC)

The Information Component (IC) statistic is an estimate of the observed-to-expected ratio of the number of target exposure AEs of interest on the log${}_2$-scale under independence between the target exposure and AEs of interest based on information theory [(Bate et al., 1998)](https://doi.org/10.1007/s002280050466)
$$
\text{IC}_{XY} = \log_2 \frac{P_{X, Y}(a_t + b_t,a_t + c_t)}{P_X(a_t + b_t) P_Y(a_t + c_t)}
$$
where $P_X(X=x)$ denotes the marginal probability of an observed count $x$ for the target exposure, $P_Y(Y=y)$ denotes the marginal probability of an observed count $y$ for the AE of interest, and $P_{X,Y}(X=x, Y=y)$ denotes the joint probability.

The BCPNN IC of [Noren et al. (2006)](https://doi.org/10.1002/sim.2473) uses a Bayesian inference based *maximum a posteriori* (m.a.p.) central estimate of the IC,  
$$
\widehat{\text{IC}}_t = \log_2 \frac{\text{E}\left[ \hat{p}_a \right]}{\text{E}\left[ \hat{p}_a + \hat{p}_b\right]\text{E}\left[ \hat{p}_a + \hat{p}_c\right]}
$$

where $p_a$, $p_b$ and $p_c$ are the (assumed constant over time) underlying probabilities of the multinomial-distributed observed events $a_t$, $b_t$ and $c_t$, respectively ($p_d$ corresponding to the count $d_t$ also included). The underlying probabilities are modelled using Dirichlet priors resulting in a Dirichlet posterior distribution. The one-sided null hypothesis of the joint probability target exposure and AEs of interest is equal or less than the marginal products ($H_0: \text{IC}_t \leq 0$) can be rejected when the $\alpha$ quantile of the Markov Chain Monte Carlo (MCMC) empirical distribution is greater than 0. Similarly to the rejection rule for the PRR, this threshold corresponds to the lower bound of the $100(1-2\alpha)$\% equal-tailed credible region in a two-sided hypothesis test.



## maxSPRT

[Kulldorff et al. (2011)](https://doi.org/10.1080/07474946.2011.539924) outlined that the relative risk (RR) at a given point-in-time for accumulated binary data (that is, "success"/"failure" events or AE of interest or not) of a target group relative to a comparator has the maximum likelihood estimate of 

$$
\widehat{\text{RR}} = z \frac{C_n}{n - C_n}
$$

where 

* $z$ is the ratio of the total AEs for the comparator to the total AEs for the target,
* $C_n$ is the count of target exposure AEs in $X$,
* $n$ is the count of all AEs in $X$ (target and comparator exposure), and
* $n - C_n$ is therefore the count of comparator exposure AEs in $X$.

In the context of our data, the values $z$, $C_n$ and $n$ are the quantities $\frac{c_t + d_t}{a_t + b_t}$, $a_t$ and $a_t + c_t$, respectively, at time $t$.

Therefore the RR maximum likelihood estimate at time $t$ can be re-written
$$
\begin{aligned}
\widehat{\text{RR}}_t 
&= 
\frac{c_t + d_t}{a_t + b_t} \times \frac{a_t}{c_t}
\\
&= 
\frac{\frac{1}{a_t + b_t}}{\frac{1}{c_t + d_t}} \times \frac{a_t}{c_t}
\\
&= 
\frac{\frac{a_t}{a_t + b_t}}{\frac{c_t}{c_t + d_t}} 
\\
\end{aligned}
$$
which is the PRR estimate at time $t$ as before.

The (maximised) log-likelihood ratio statistic of $\widehat{\text{PRR}}_t$ (equivalently, $\widehat{\text{RR}}_t$) can be determined calculated as

$$
\text{LLR}_t = 
a_t  \ln \left(\frac{a_t}{a_t + c_t}\right) + 
c_t  \ln \left(\frac{c_t}{a_t + c_t} \right) - 
a_t  \ln\left(\frac{a_t + b_t}{a_t + b_t +c_t + d_t}\right) - 
c_t \ln\left(\frac{c_t + d_t}{a_t + b_t + c_t + d_t}\right)
$$



\newpage


# Analysis choices:

* Data structures - cumulative vs snapshot
* Threshold choose
* How many "looks"
* how to choose alpha spending
* sample size limitations for maxsprt - not an issue now can use MCMC method of `EmpiricalCalibration`



\newpage


# Plots



```{R, time_to_sig_plot}
#| fig.width: 7
#| fig.height: 7
```



```{R, stat_over_time_plot}
#| fig.width: 7
#| fig.height: 7
```





\newpage

# Session information


```{R}
# Sys.info()[!(names(Sys.info()) %in% c("login", "nodename"))] %>% 
#   as.data.frame(.)
format(Sys.time(), '%d %b %Y')
sessionInfo()
```





